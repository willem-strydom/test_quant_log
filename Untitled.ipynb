{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9482354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in loop\n",
      "[[ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]]\n",
      "[[ 3.77849939]\n",
      " [ 1.32593169]\n",
      " [ 0.49599751]\n",
      " [-2.01216127]\n",
      " [ 0.82239618]\n",
      " [ 0.34708038]\n",
      " [-0.47098688]\n",
      " [-1.07741975]\n",
      " [-1.02271834]\n",
      " [ 0.90290901]\n",
      " [ 0.56660747]\n",
      " [ 1.94297891]\n",
      " [ 2.21016808]\n",
      " [ 0.28408768]\n",
      " [-1.1297544 ]\n",
      " [ 0.27990904]\n",
      " [-1.30529788]\n",
      " [-0.22145401]\n",
      " [-0.34966898]\n",
      " [ 0.76749361]\n",
      " [-0.04604862]\n",
      " [ 0.82659028]\n",
      " [ 0.08019299]\n",
      " [ 0.83139697]\n",
      " [ 1.23922809]\n",
      " [-0.20713579]\n",
      " [-0.84335886]\n",
      " [ 0.28035624]\n",
      " [ 0.35205923]\n",
      " [ 0.24304275]\n",
      " [ 1.32685246]\n",
      " [-3.04881726]\n",
      " [ 0.803841  ]\n",
      " [ 0.48946531]\n",
      " [-0.30219094]\n",
      " [ 0.10022112]\n",
      " [-1.17560604]\n",
      " [-1.68600572]\n",
      " [ 0.74374392]\n",
      " [ 0.84456895]\n",
      " [-1.81144109]\n",
      " [-0.40890716]\n",
      " [ 0.57200602]\n",
      " [ 0.21774126]\n",
      " [ 1.08407013]\n",
      " [ 2.01205178]\n",
      " [ 0.23933368]\n",
      " [-0.31890032]\n",
      " [ 2.53597312]\n",
      " [ 2.07279803]\n",
      " [-2.09583864]\n",
      " [ 0.18869706]\n",
      " [ 1.35188775]\n",
      " [ 0.71009547]\n",
      " [ 1.21870851]\n",
      " [-1.21341146]\n",
      " [-0.38643139]\n",
      " [-1.13355084]\n",
      " [ 0.87000401]\n",
      " [ 1.74387483]\n",
      " [-0.77349018]]\n",
      "[[ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "[3] [498]\n",
      "0.3285024154589372\n",
      "0.09178743961352658\n",
      "0.463768115942029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from experiment import experiment\n",
    "from experiment import test_loss\n",
    "import random\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "\n",
    "#loading sonar data\n",
    "sonar_data = pd.read_csv(\"sonar.csv\").to_numpy()\n",
    "sonar_x = sonar_data[:,:-1]\n",
    "sonar_x = scaler.fit_transform(sonar_x)\n",
    "#add intercept\n",
    "bias = np.ones((sonar_data.shape[0],1))\n",
    "sonar_x = np.hstack((bias, sonar_x)).astype(float)\n",
    "sonar_y = sonar_data[:,-1]\n",
    "#convert labels to +1 -1\n",
    "sonar_y = np.where(sonar_y == \"M\",1,-1)\n",
    "\n",
    "\n",
    "p = sonar_x.shape[0]\n",
    "\n",
    "normal_iters, quant_iters,  w_quant, w_quant_prev, w_quant_prev2, w = experiment(sonar_x, sonar_y,1,p)\n",
    "\n",
    "\"\"\"print(f\"sonar normal iterations: {np.mean(normal_iters)}, quantized iterations: {np.mean(quant_iters)}, \"\n",
    "      f\"normal loss {np.mean(normal_loss)}, quantized loss {np.mean(quant_loss)}, quantized iters {quant_iters}\")\"\"\"\n",
    "got_same_w = (np.sign(w) == w_quant)\n",
    "\n",
    "# a bunch of diagnostic outputs\n",
    "print(got_same_w)\n",
    "print(w)\n",
    "print(w_quant)\n",
    "print(quant_iters,normal_iters)\n",
    "print(test_loss(np.sign(w), sonar_x.T,sonar_y.T))\n",
    "print(test_loss(w, sonar_x.T,sonar_y.T))\n",
    "print(test_loss(w_quant, sonar_x.T,sonar_y.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd50a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "loop = np.hstack((w_quant, w_quant_prev, w_quant_prev2))\n",
    "print(loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9d4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2173913  -0.18732306]\n",
      " [ 0.12352329  0.1010598 ]\n",
      " [ 0.13902607  0.11789212]\n",
      " [ 0.15001397  0.12812934]\n",
      " [ 0.15549445  0.13152046]\n",
      " [ 0.12637818  0.10366385]\n",
      " [ 0.09824511  0.07659508]\n",
      " [ 0.06208697  0.04680495]\n",
      " [ 0.07840574  0.06261806]\n",
      " [ 0.09988189  0.07708292]\n",
      " [ 0.08945453  0.06610235]\n",
      " [ 0.07348982  0.05098953]\n",
      " [ 0.05680718  0.03744682]\n",
      " [ 0.0367197   0.0242376 ]\n",
      " [ 0.06770857  0.0535337 ]\n",
      " [ 0.03278327  0.02418472]\n",
      " [ 0.0035546  -0.00146649]\n",
      " [-0.00849152 -0.01400384]\n",
      " [-0.02950449 -0.0320074 ]\n",
      " [-0.06545878 -0.06196295]\n",
      " [-0.09760791 -0.08944533]\n",
      " [-0.11972968 -0.10890895]\n",
      " [-0.10612511 -0.09881658]\n",
      " [-0.08104291 -0.07634174]\n",
      " [-0.0797777  -0.07553716]\n",
      " [-0.07315128 -0.07145458]\n",
      " [-0.06754718 -0.06783995]\n",
      " [-0.05699306 -0.05597674]\n",
      " [-0.02728255 -0.02674947]\n",
      " [ 0.00677779  0.00368316]\n",
      " [ 0.0406179   0.03115689]\n",
      " [ 0.09379141  0.07824855]\n",
      " [ 0.09990807  0.08557694]\n",
      " [ 0.10211129  0.08812471]\n",
      " [ 0.06755093  0.06092573]\n",
      " [ 0.06088231  0.05605914]\n",
      " [ 0.06868523  0.06592061]\n",
      " [ 0.0705332   0.06899812]\n",
      " [ 0.07973149  0.07503817]\n",
      " [ 0.08553617  0.07666482]\n",
      " [ 0.07975382  0.07041985]\n",
      " [ 0.08919827  0.07875591]\n",
      " [ 0.0805094   0.06981913]\n",
      " [ 0.09848938  0.08009194]\n",
      " [ 0.11267764  0.08951796]\n",
      " [ 0.09725776  0.07545464]\n",
      " [ 0.12047085  0.09820996]\n",
      " [ 0.11914398  0.09892316]\n",
      " [ 0.10124383  0.08153419]\n",
      " [ 0.09968371  0.07898815]\n",
      " [ 0.1128561   0.0943656 ]\n",
      " [ 0.14288258  0.12190697]\n",
      " [ 0.13933167  0.1188208 ]\n",
      " [ 0.10873957  0.09056003]\n",
      " [ 0.06951154  0.06021385]\n",
      " [ 0.11349918  0.09912708]\n",
      " [ 0.10499195  0.09094102]\n",
      " [ 0.10995828  0.09543963]\n",
      " [ 0.12172365  0.10369971]\n",
      " [ 0.10779734  0.09332459]\n",
      " [ 0.14441432  0.12441367]]\n"
     ]
    }
   ],
   "source": [
    "# comparing actual gradient to quantized gradient for w*\n",
    "\n",
    "from QuantLog import quantlogistic\n",
    "from NormalLog import normallogistic\n",
    "quant_loss, quant_gradient = quantlogistic(np.sign(w),sonar_x.T,sonar_y.T)\n",
    "normal_loss, normal_gradient = normallogistic(np.sign(w),sonar_x.T,sonar_y.T)\n",
    "\n",
    "print(np.hstack((quant_gradient,normal_gradient)))\n",
    "\n",
    "# the gradient is close, but the sign is not always preserved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23347bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.45410628  3.84490194]\n",
      " [-1.         -0.31806393  1.6141879 ]\n",
      " [-1.         -0.34168856 -0.18982025]\n",
      " [-1.         -0.35203489 -1.5833871 ]\n",
      " [-1.         -0.37687362  0.59673562]\n",
      " [-1.         -0.32759823  0.41390935]\n",
      " [-1.         -0.24545113 -0.22406774]\n",
      " [-1.         -0.18547013 -1.20908623]\n",
      " [-1.         -0.23439805 -1.05248432]\n",
      " [-1.         -0.27978834  0.81876055]\n",
      " [-1.         -0.26266432  0.86796169]\n",
      " [-1.         -0.26679845  1.682767  ]\n",
      " [-1.         -0.23103454  2.04012025]\n",
      " [-1.         -0.18435372  0.43908924]\n",
      " [-1.         -0.22467131 -1.07561721]\n",
      " [-1.         -0.17416503  0.01528204]\n",
      " [-1.         -0.11855267 -1.00574773]\n",
      " [-1.         -0.09156369 -0.48443955]\n",
      " [-1.         -0.06094234 -0.19544868]\n",
      " [ 1.         -0.05188993  0.55371924]\n",
      " [ 1.         -0.02523824  0.31755405]\n",
      " [ 1.          0.02192446  0.43172588]\n",
      " [ 1.          0.06201612  0.18118505]\n",
      " [ 1.          0.09061158  0.90119396]\n",
      " [ 1.          0.14156307  1.00880456]\n",
      " [ 1.          0.15262137 -0.01311483]\n",
      " [ 1.          0.15443187 -0.89868677]\n",
      " [ 1.          0.1640614   0.3057455 ]\n",
      " [ 1.          0.14805898  0.24068198]\n",
      " [ 1.          0.1131521   0.16774086]\n",
      " [ 1.          0.04837402  1.53637629]\n",
      " [-1.          0.02501968 -3.21689094]\n",
      " [-1.         -0.03645167  0.90909815]\n",
      " [-1.         -0.08323099  0.39730015]\n",
      " [-1.         -0.05202748 -0.33825467]\n",
      " [-1.         -0.05873096  0.3526798 ]\n",
      " [-1.         -0.04569405 -1.48030335]\n",
      " [-1.         -0.07884759 -1.59409271]\n",
      " [-1.         -0.16897714  0.90262318]\n",
      " [-1.         -0.19777633  0.75490324]\n",
      " [-1.         -0.15507141 -1.91834924]\n",
      " [-1.         -0.19853366 -0.49718057]\n",
      " [-1.         -0.19366023  0.55684603]\n",
      " [-1.         -0.21730822  0.48587213]\n",
      " [-1.         -0.25833523  0.97162428]\n",
      " [-1.         -0.28221928  2.0110234 ]\n",
      " [-1.         -0.32259295 -0.15897829]\n",
      " [-1.         -0.31287061  0.20039869]\n",
      " [-1.         -0.28102082  1.86653934]\n",
      " [-1.         -0.29157674  2.85955147]\n",
      " [-1.         -0.270426   -2.36938798]\n",
      " [-1.         -0.35488962  0.43843834]\n",
      " [-1.         -0.33725458  1.11736657]\n",
      " [-1.         -0.24455737  0.763773  ]\n",
      " [-1.         -0.23631946  1.231012  ]\n",
      " [-1.         -0.29592384 -0.95726331]\n",
      " [-1.         -0.29461167 -0.39125027]\n",
      " [-1.         -0.26438296 -1.00082733]\n",
      " [-1.         -0.32726429  0.59087431]\n",
      " [-1.         -0.28511731  1.60604512]\n",
      " [-1.         -0.34238154 -0.59477393]]\n"
     ]
    }
   ],
   "source": [
    "#get the quantized gradient of the final w_quant\n",
    "\n",
    "loss_quant_w, gradient_quant_w = quantlogistic(w_quant,sonar_x.T,sonar_y.T)\n",
    "\n",
    "vis_stationary_pts = np.hstack((w_quant,gradient_quant_w, w))\n",
    "print(vis_stationary_pts)\n",
    "\n",
    "#does not look like it should be a stationary point... also the alg terminated on max_iters\n",
    "\n",
    "# reason - I think that if any of the values in w* are between -1 and 1, the gradient will bounce back and forth between\n",
    "#the quantized feasible points. \n",
    "\n",
    "# problem - why is the gradient sign agreeing with w_quant even when the value of w* at that feature is not in [-1,1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c31a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
