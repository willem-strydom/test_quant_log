{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9482354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in loop\n",
      "[[ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]]\n",
      "[[ 3.91154261]\n",
      " [ 1.2696732 ]\n",
      " [ 0.21815129]\n",
      " [-1.59962031]\n",
      " [ 0.44652279]\n",
      " [ 0.59887052]\n",
      " [-0.64157358]\n",
      " [-0.91438508]\n",
      " [-1.2228932 ]\n",
      " [ 1.12874928]\n",
      " [ 0.48051162]\n",
      " [ 1.99290778]\n",
      " [ 1.95475957]\n",
      " [ 0.5096081 ]\n",
      " [-1.1360824 ]\n",
      " [-0.17500569]\n",
      " [-0.82157123]\n",
      " [-0.31320642]\n",
      " [-0.27020271]\n",
      " [ 0.32804385]\n",
      " [ 0.61648105]\n",
      " [ 0.06551609]\n",
      " [ 0.77953737]\n",
      " [ 0.40645657]\n",
      " [ 1.80054502]\n",
      " [-0.96089384]\n",
      " [-0.0258013 ]\n",
      " [-0.50898782]\n",
      " [ 0.80412668]\n",
      " [ 0.21897001]\n",
      " [ 1.05951494]\n",
      " [-2.64754439]\n",
      " [ 0.60332462]\n",
      " [ 0.50840837]\n",
      " [-0.41289312]\n",
      " [ 0.40505105]\n",
      " [-1.47033751]\n",
      " [-1.47167772]\n",
      " [ 0.35292352]\n",
      " [ 1.44968182]\n",
      " [-2.18797461]\n",
      " [-0.40357456]\n",
      " [ 0.95924843]\n",
      " [ 0.21144304]\n",
      " [ 1.05405704]\n",
      " [ 2.11351553]\n",
      " [-0.09866854]\n",
      " [-0.65936616]\n",
      " [ 2.45746998]\n",
      " [ 2.39151972]\n",
      " [-2.19200635]\n",
      " [ 0.48158385]\n",
      " [ 1.2530477 ]\n",
      " [ 0.70832262]\n",
      " [ 1.14371958]\n",
      " [-1.02690856]\n",
      " [-0.34898659]\n",
      " [-0.94665576]\n",
      " [ 0.8337231 ]\n",
      " [ 1.11434856]\n",
      " [-0.11361713]]\n",
      "[[ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "[4] [472]\n",
      "0.2898550724637681\n",
      "0.10144927536231885\n",
      "0.463768115942029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from experiment import experiment\n",
    "from experiment import test_loss\n",
    "import random\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "\n",
    "#loading sonar data\n",
    "sonar_data = pd.read_csv(\"sonar.csv\").to_numpy()\n",
    "sonar_x = sonar_data[:,:-1]\n",
    "sonar_x = scaler.fit_transform(sonar_x)\n",
    "#add intercept\n",
    "bias = np.ones((sonar_data.shape[0],1))\n",
    "sonar_x = np.hstack((bias, sonar_x)).astype(float)\n",
    "sonar_y = sonar_data[:,-1]\n",
    "#convert labels to +1 -1\n",
    "sonar_y = np.where(sonar_y == \"M\",1,-1)\n",
    "\n",
    "\n",
    "p = sonar_x.shape[0]\n",
    "\n",
    "normal_iters, quant_iters,  w_quant, w_quant_prev, w_quant_prev2, w = experiment(sonar_x, sonar_y,1,p)\n",
    "\n",
    "\"\"\"print(f\"sonar normal iterations: {np.mean(normal_iters)}, quantized iterations: {np.mean(quant_iters)}, \"\n",
    "      f\"normal loss {np.mean(normal_loss)}, quantized loss {np.mean(quant_loss)}, quantized iters {quant_iters}\")\"\"\"\n",
    "got_same_w = (np.sign(w) == w_quant)\n",
    "\n",
    "# a bunch of diagnostic outputs\n",
    "print(got_same_w)\n",
    "print(w)\n",
    "print(w_quant)\n",
    "print(quant_iters,normal_iters)\n",
    "print(test_loss(np.sign(w), sonar_x.T,sonar_y.T))\n",
    "print(test_loss(w, sonar_x.T,sonar_y.T))\n",
    "print(test_loss(w_quant, sonar_x.T,sonar_y.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd50a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [-1. -1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "#check loop behavior\n",
    "\n",
    "loop = np.hstack((w_quant, w_quant_prev, w_quant_prev2))\n",
    "print(loop)\n",
    "\n",
    "# it seems like almost all of the bits are being flipped every time, which is not expected \n",
    "# given the w* in the previous output.\n",
    "# I thought that any feature with w* not in [-1,1] would not be flipped repeatedly, of which there are quite a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf65dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((w_quant_prev , w_quant, np.sign(w))))\n",
    "\n",
    "# the w's that we are stuck looping through are not np.sign(w)\n",
    "\n",
    "# I think that this is due to the random init of w, and that this behavior\n",
    "# can be seen in 2 dimensions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9d4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30676329 -0.26158379]\n",
      " [ 0.17379191  0.14448501]\n",
      " [ 0.20356014  0.16874904]\n",
      " [ 0.22150171  0.18494393]\n",
      " [ 0.22905281  0.19249102]\n",
      " [ 0.19481905  0.16224272]\n",
      " [ 0.14806354  0.1205706 ]\n",
      " [ 0.09412055  0.07985025]\n",
      " [ 0.11901688  0.10135632]\n",
      " [ 0.13626329  0.11375859]\n",
      " [ 0.11505467  0.09612846]\n",
      " [ 0.09834682  0.07960135]\n",
      " [ 0.07936467  0.06066084]\n",
      " [ 0.07066791  0.05023992]\n",
      " [ 0.12728151  0.10033259]\n",
      " [ 0.09403087  0.07357391]\n",
      " [ 0.07071793  0.0548034 ]\n",
      " [ 0.05751625  0.04501018]\n",
      " [ 0.02881561  0.02195713]\n",
      " [-0.00671023 -0.00970616]\n",
      " [-0.05143035 -0.04656039]\n",
      " [-0.0881449  -0.07754422]\n",
      " [-0.10061827 -0.08772867]\n",
      " [-0.10312093 -0.08957719]\n",
      " [-0.12664443 -0.11134076]\n",
      " [-0.13368278 -0.11725256]\n",
      " [-0.14484373 -0.12556618]\n",
      " [-0.16135971 -0.13887113]\n",
      " [-0.15027904 -0.12535706]\n",
      " [-0.10488719 -0.08487957]\n",
      " [-0.03304061 -0.02274921]\n",
      " [ 0.04603378  0.04385089]\n",
      " [ 0.08819491  0.07885445]\n",
      " [ 0.12539309  0.11144712]\n",
      " [ 0.12517351  0.11002881]\n",
      " [ 0.14147445  0.12553178]\n",
      " [ 0.14943704  0.13191877]\n",
      " [ 0.14344065  0.12594856]\n",
      " [ 0.15857662  0.13707392]\n",
      " [ 0.15712043  0.1359214 ]\n",
      " [ 0.14528012  0.12690773]\n",
      " [ 0.16282151  0.13971439]\n",
      " [ 0.13906142  0.11637369]\n",
      " [ 0.1428994   0.12067181]\n",
      " [ 0.15880102  0.135545  ]\n",
      " [ 0.15144728  0.12681893]\n",
      " [ 0.18270767  0.15320509]\n",
      " [ 0.16927809  0.1420967 ]\n",
      " [ 0.13783018  0.11219563]\n",
      " [ 0.14206093  0.11677826]\n",
      " [ 0.16808959  0.14373646]\n",
      " [ 0.211165    0.17544756]\n",
      " [ 0.20346021  0.16882642]\n",
      " [ 0.15636489  0.13006749]\n",
      " [ 0.13499732  0.11103078]\n",
      " [ 0.19317647  0.16047462]\n",
      " [ 0.17647715  0.14787338]\n",
      " [ 0.18010266  0.15146866]\n",
      " [ 0.20234029  0.16814316]\n",
      " [ 0.18040085  0.14962045]\n",
      " [ 0.21500932  0.1849289 ]]\n"
     ]
    }
   ],
   "source": [
    "# comparing actual gradient to quantized gradient for w*\n",
    "\n",
    "from QuantLog import quantlogistic\n",
    "from NormalLog import normallogistic\n",
    "quant_loss, quant_gradient = quantlogistic(np.sign(w),sonar_x.T,sonar_y.T)\n",
    "normal_loss, normal_gradient = normallogistic(np.sign(w),sonar_x.T,sonar_y.T)\n",
    "\n",
    "print(np.hstack((quant_gradient,normal_gradient)))\n",
    "\n",
    "# the gradient is close, but the sign is not always preserved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23347bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  4.54106280e-01  3.99876282e+00]\n",
      " [-1.00000000e+00 -3.18063928e-01  1.83419517e+00]\n",
      " [-1.00000000e+00 -3.41688564e-01 -4.02787789e-01]\n",
      " [-1.00000000e+00 -3.52034889e-01 -1.59465715e+00]\n",
      " [-1.00000000e+00 -3.76873617e-01  9.75436675e-01]\n",
      " [-1.00000000e+00 -3.27598226e-01  2.11900301e-03]\n",
      " [-1.00000000e+00 -2.45451135e-01 -1.11503931e-02]\n",
      " [-1.00000000e+00 -1.85470126e-01 -1.26712670e+00]\n",
      " [-1.00000000e+00 -2.34398053e-01 -1.39458929e+00]\n",
      " [-1.00000000e+00 -2.79788335e-01  1.44214173e+00]\n",
      " [-1.00000000e+00 -2.62664321e-01  6.60521524e-01]\n",
      " [-1.00000000e+00 -2.66798450e-01  1.55393330e+00]\n",
      " [-1.00000000e+00 -2.31034541e-01  1.91279139e+00]\n",
      " [-1.00000000e+00 -1.84353723e-01  5.45175569e-01]\n",
      " [-1.00000000e+00 -2.24671309e-01 -7.61755469e-01]\n",
      " [-1.00000000e+00 -1.74165032e-01 -2.88014531e-01]\n",
      " [-1.00000000e+00 -1.18552672e-01 -5.49289433e-01]\n",
      " [-1.00000000e+00 -9.15636887e-02 -1.15105125e+00]\n",
      " [-1.00000000e+00 -6.09423427e-02  1.65618161e-01]\n",
      " [ 1.00000000e+00 -5.18899327e-02  8.53023960e-01]\n",
      " [ 1.00000000e+00 -2.52382370e-02 -4.21793745e-02]\n",
      " [ 1.00000000e+00  2.19244650e-02  3.96787946e-01]\n",
      " [ 1.00000000e+00  6.20161241e-02  3.14200673e-01]\n",
      " [ 1.00000000e+00  9.06115767e-02  9.24131173e-01]\n",
      " [ 1.00000000e+00  1.41563067e-01  9.90439243e-01]\n",
      " [ 1.00000000e+00  1.52621367e-01 -2.13994056e-01]\n",
      " [ 1.00000000e+00  1.54431871e-01 -4.62977558e-01]\n",
      " [ 1.00000000e+00  1.64061402e-01 -3.71550552e-01]\n",
      " [ 1.00000000e+00  1.48058981e-01  8.35667885e-01]\n",
      " [ 1.00000000e+00  1.13152095e-01 -2.55509736e-01]\n",
      " [ 1.00000000e+00  4.83740233e-02  1.63273916e+00]\n",
      " [-1.00000000e+00  2.50196791e-02 -3.17925418e+00]\n",
      " [-1.00000000e+00 -3.64516686e-02  8.89917019e-01]\n",
      " [-1.00000000e+00 -8.32309877e-02  2.96543304e-01]\n",
      " [-1.00000000e+00 -5.20274750e-02 -2.91841477e-01]\n",
      " [-1.00000000e+00 -5.87309564e-02  2.87610407e-01]\n",
      " [-1.00000000e+00 -4.56940549e-02 -1.66929803e+00]\n",
      " [-1.00000000e+00 -7.88475942e-02 -1.16829581e+00]\n",
      " [-1.00000000e+00 -1.68977138e-01  4.03924335e-01]\n",
      " [-1.00000000e+00 -1.97776331e-01  1.16023146e+00]\n",
      " [-1.00000000e+00 -1.55071411e-01 -2.18926652e+00]\n",
      " [-1.00000000e+00 -1.98533661e-01 -2.74174609e-01]\n",
      " [-1.00000000e+00 -1.93660231e-01  2.33125645e-01]\n",
      " [-1.00000000e+00 -2.17308217e-01  7.96812691e-01]\n",
      " [-1.00000000e+00 -2.58335232e-01  7.89197978e-01]\n",
      " [-1.00000000e+00 -2.82219283e-01  1.68961480e+00]\n",
      " [-1.00000000e+00 -3.22592955e-01  8.52530036e-01]\n",
      " [-1.00000000e+00 -3.12870608e-01 -3.38662371e-01]\n",
      " [-1.00000000e+00 -2.81020815e-01  1.91689730e+00]\n",
      " [-1.00000000e+00 -2.91576742e-01  3.05813041e+00]\n",
      " [-1.00000000e+00 -2.70425999e-01 -2.76101313e+00]\n",
      " [-1.00000000e+00 -3.54889620e-01  3.13108398e-01]\n",
      " [-1.00000000e+00 -3.37254578e-01  1.10894513e+00]\n",
      " [-1.00000000e+00 -2.44557375e-01  8.42551220e-01]\n",
      " [-1.00000000e+00 -2.36319462e-01  1.22959147e+00]\n",
      " [-1.00000000e+00 -2.95923845e-01 -9.44113273e-01]\n",
      " [-1.00000000e+00 -2.94611669e-01 -2.80970795e-01]\n",
      " [-1.00000000e+00 -2.64382960e-01 -1.05391474e+00]\n",
      " [-1.00000000e+00 -3.27264285e-01  5.01219605e-01]\n",
      " [-1.00000000e+00 -2.85117313e-01  1.44873547e+00]\n",
      " [-1.00000000e+00 -3.42381542e-01 -4.27158434e-01]]\n"
     ]
    }
   ],
   "source": [
    "#get the quantized gradient of the final w_quant\n",
    "\n",
    "loss_quant_w, gradient_quant_w = quantlogistic(w_quant,sonar_x.T,sonar_y.T)\n",
    "\n",
    "vis_stationary_pts = np.hstack((w_quant,gradient_quant_w, w))\n",
    "print(vis_stationary_pts)\n",
    "\n",
    "\n",
    "# reason - I think that if any of the values in w* are between -1 and 1, the gradient will bounce back and forth between\n",
    "# the quantized feasible points. \n",
    "\n",
    "# problem - why is the quant gradient at w_quant point towards w* in some instances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59c31a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3719806763285024 [[ 0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [ 0.01010101]\n",
      " [-1.        ]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]\n",
      " [-0.01010101]]\n"
     ]
    }
   ],
   "source": [
    "# line search: iterate along the line between w_quant and w_wuant prev to try to find\n",
    "# the best w in that search path\n",
    "\n",
    "from QuantLog import test_loss\n",
    "\n",
    "ts = np.linspace(0,1,100)\n",
    "loss = []\n",
    "ws =[]\n",
    "for t in ts:\n",
    "    w_current = t*w_quant + (1-t)*w_quant_prev\n",
    "    loss.append(test_loss(w_current, sonar_x.T, sonar_y.T))\n",
    "    ws.append(w_current)\n",
    "\n",
    "best_loss = np.min(loss)\n",
    "best_w = ws[np.argmin(loss)]\n",
    "\n",
    "print(best_loss,best_w)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# is not super great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d340b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
